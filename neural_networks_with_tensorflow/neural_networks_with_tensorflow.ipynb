{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import Imputer, LabelBinarizer, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_boston, load_iris\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "####### Mandatory tensorflow setup\n",
    "# 1) reset graph\n",
    "# 2) setup tf variables\n",
    "# 3) init\n",
    "# 4) \"with tf.Session() as sess:\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = tf.multiply(x, y)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    results = f.eval()\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "\n",
    "### MUST reshape target (y) to be list of lists for tensorflow \n",
    "target = data.target.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, target)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name='X')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None), name='y')\n",
    "\n",
    "# first hidden layer\n",
    "# X == features coming in, 13 == number of features == neurons\n",
    "h1 = tf.layers.dense(X, 13, name='hidden1', activation=tf.nn.relu)\n",
    "\n",
    "# last/output always with 1 neuron for regression problem\n",
    "y_hat = tf.layers.dense(h1, 1, name='y_hat', activation=None)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y, y_hat)\n",
    "\n",
    "gd = tf.train.AdamOptimizer(.1) #could pass in learning rate as param\n",
    "training_op = gd.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  | training loss: 498.82523  | test loss: 578.54834\n",
      "epoch: 10  | training loss: 122.30233  | test loss: 123.692345\n",
      "epoch: 20  | training loss: 42.74601  | test loss: 45.783573\n",
      "epoch: 30  | training loss: 22.761417  | test loss: 32.743988\n",
      "epoch: 40  | training loss: 16.274607  | test loss: 22.88149\n",
      "epoch: 50  | training loss: 12.187437  | test loss: 18.324211\n",
      "epoch: 60  | training loss: 10.561711  | test loss: 19.790585\n",
      "epoch: 70  | training loss: 9.381224  | test loss: 16.903927\n",
      "epoch: 80  | training loss: 8.732194  | test loss: 16.200596\n",
      "epoch: 90  | training loss: 8.143583  | test loss: 16.18833\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    #train model\n",
    "    for epoch in range(100):\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "        if (epoch % 10 == 0):\n",
    "            training_loss = sess.run(loss, feed_dict={X: X_train, y: y_train})\n",
    "            test_loss = sess.run(loss, feed_dict={X: X_test, y: y_test})\n",
    "            print('epoch:',epoch,' | training loss:', training_loss, ' | test loss:', test_loss)\n",
    "            \n",
    "    saver.save(sess, './boston.ckpt')\n",
    "    pred = sess.run(y_hat, feed_dict={X: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from boston.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8251895825475513"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'boston.ckpt')\n",
    "    pred = sess.run(y_hat, feed_dict={X: X_test})\n",
    "    \n",
    "metrics.r2_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "target = 1 - data.target\n",
    "\n",
    "### MUST reshape target (y) to be list of lists for tensorflow \n",
    "target = data.target.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, target)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#None == allow dynamic number of rows; X_train.shape[1] == number of features\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name='X')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None), name='y')\n",
    "\n",
    "# first hidden layer\n",
    "# X == features coming in, 30 == number of features == neurons\n",
    "h1 = tf.layers.dense(X, 30, name='hidden1', activation=tf.nn.relu)\n",
    "\n",
    "# second hidden layer\n",
    "# X == features coming in, 26 == number of neurons == arbitrary\n",
    "h2 = tf.layers.dense(h1, 26, name='hidden2', activation=tf.nn.relu)\n",
    "\n",
    "# last/output always with 1 neuron for binary classification problem\n",
    "y_hat = tf.layers.dense(h2, 1, name='y_hat', activation=tf.nn.sigmoid)\n",
    "\n",
    "loss = tf.losses.log_loss(y, y_hat)\n",
    "\n",
    "gd = tf.train.AdamOptimizer(.01) #could pass in learning rate as param\n",
    "training_op = gd.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  | training loss: 0.6027077  | test loss: 0.5729999\n",
      "epoch: 10  | training loss: 0.11087423  | test loss: 0.11399212\n",
      "epoch: 20  | training loss: 0.059190013  | test loss: 0.06608006\n",
      "epoch: 30  | training loss: 0.04484703  | test loss: 0.055342205\n",
      "epoch: 40  | training loss: 0.032626305  | test loss: 0.054871682\n",
      "epoch: 50  | training loss: 0.02374843  | test loss: 0.062073115\n",
      "epoch: 60  | training loss: 0.016426945  | test loss: 0.0688743\n",
      "epoch: 70  | training loss: 0.010725553  | test loss: 0.07921874\n",
      "epoch: 80  | training loss: 0.007073321  | test loss: 0.0888902\n",
      "epoch: 90  | training loss: 0.0046950025  | test loss: 0.10200834\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    #train model\n",
    "    for epoch in range(100):\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "        if (epoch % 10 == 0):\n",
    "            training_loss = sess.run(loss, feed_dict={X: X_train, y: y_train})\n",
    "            test_loss = sess.run(loss, feed_dict={X: X_test, y: y_test})\n",
    "            print('epoch:',epoch,' | training loss:', training_loss, ' | test loss:', test_loss)\n",
    "            \n",
    "    saver.save(sess, './breast_cancer.ckpt')\n",
    "    pred = sess.run(y_hat, feed_dict={X: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from breast_cancer.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.965034965034965"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'breast_cancer.ckpt')\n",
    "    pred = sess.run(y_hat, feed_dict={X: X_test})\n",
    "    \n",
    "classes = (pred > .5).astype(int)\n",
    "metrics.accuracy_score(y_test, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "target = to_categorical(data.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, target)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#None == allow dynamic number of rows; X_train.shape[1] == number of features\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name='X')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 3), name='y') # shape has 3 for 3 classes\n",
    "\n",
    "# first hidden layer\n",
    "# X == features coming in, 4 == number of features == neurons\n",
    "h1 = tf.layers.dense(X, 4, name='hidden1', activation=tf.nn.relu)\n",
    "\n",
    "# last/output with 3 neurons == one for each class\n",
    "y_hat = tf.layers.dense(h1, 3, name='y_hat', activation=None) #FYI: activation is None because softmax is taken care of in the loss function in tf\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(y, y_hat)\n",
    "\n",
    "gd = tf.train.AdamOptimizer(.01) #could pass in learning rate as param\n",
    "training_op = gd.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### FYI: this/batching is required/good for large datasets only \n",
    "kf = StratifiedKFold()\n",
    "batches = []\n",
    "for train, test in kf.split(X_train, y_train.argmax(axis=1)):\n",
    "#     print('train',train)\n",
    "#     print('test',test)\n",
    "    batches.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.92804366 test loss 1.0773953\n",
      "training loss 0.46016827 test loss 0.5540002\n",
      "training loss 0.30851045 test loss 0.36973476\n",
      "training loss 0.21520232 test loss 0.27755782\n",
      "training loss 0.13728611 test loss 0.20214576\n",
      "training loss 0.099481635 test loss 0.16531575\n",
      "training loss 0.0791089 test loss 0.14572659\n",
      "training loss 0.067743056 test loss 0.13391523\n",
      "training loss 0.060723662 test loss 0.12670164\n",
      "training loss 0.05573219 test loss 0.12180179\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "###### WITHOUT BATCHING\n",
    "# with tf.Session() as sess:\n",
    "#     init.run()\n",
    "#     #train model\n",
    "#     for epoch in range(100):\n",
    "#         sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "#         if (epoch % 10 == 0):\n",
    "#             training_loss = sess.run(loss, feed_dict={X: X_train, y: y_train})\n",
    "#             test_loss = sess.run(loss, feed_dict={X: X_test, y: y_test})\n",
    "#             print('epoch:',epoch,' | training loss:', training_loss, ' | test loss:', test_loss)\n",
    "            \n",
    "#     saver.save(sess, './iris.ckpt')\n",
    "#     pred = sess.run(y_hat, feed_dict={X: X_test})\n",
    "\n",
    "###### WITH BATCHING\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(100):\n",
    "        for batch in batches:\n",
    "            X_batch = X_train[batch]\n",
    "            y_batch = y_train[batch]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            training_loss = sess.run(loss, feed_dict={X: X_train, y: y_train})\n",
    "            test_loss = sess.run(loss, feed_dict={X: X_test, y: y_test})\n",
    "            print('training loss', training_loss, 'test loss', test_loss)\n",
    "\n",
    "    saver.save(sess, './iris.ckpt')       \n",
    "    pred = sess.run(y_hat, feed_dict={X: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 2, 2, 0, 0, 0, 0, 1, 2, 0, 2, 2, 1, 2, 0, 0, 0, 2, 1,\n",
       "       2, 0, 1, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
